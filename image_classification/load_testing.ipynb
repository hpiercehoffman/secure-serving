{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8396c65-0fed-40f7-a210-b391d323c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import concurrent.futures\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ec8bc3-c0a9-454b-a50a-79c5ae89ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base64_encode(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def test_single_request(encoded_image, url):\n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, json={\"image\": encoded_image})\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return elapsed_time\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f148bc-91fd-483a-8a2e-f85183b2a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(encoded_image, url, num_requests):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(test_single_request, encoded_image, url) for _ in range(num_requests)]\n",
    "        results = [f.result() for f in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "    results = [result for result in results if result is not None]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "539dc7d0-42ae-4fd5-a195-39b90860c67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting load test with 1 concurrent requests...\n",
      "Average latency: 0.5274 seconds\n",
      "Min latency: 0.5274 seconds\n",
      "Max latency: 0.5274 seconds\n"
     ]
    }
   ],
   "source": [
    "def run_load_tests(url, sample_image, num_requests):\n",
    "\n",
    "    encoded_image = base64_encode(sample_image)\n",
    "    \n",
    "    print(f\"Starting load test with {num_requests} concurrent requests...\")\n",
    "    latencies = load_test(encoded_image, url, num_requests)\n",
    "\n",
    "    average_latency = sum(latencies) / len(latencies)\n",
    "    print(f\"Average latency: {average_latency:.4f} seconds\")\n",
    "    print(f\"Min latency: {min(latencies):.4f} seconds\")\n",
    "    print(f\"Max latency: {max(latencies):.4f} seconds\")\n",
    "\n",
    "run_load_tests(\"http://localhost:8888/predict/\", \"public/sample_images/sample_cat.jpeg\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495d8cb-01bc-47c8-a846-7abb930a3e9c",
   "metadata": {},
   "source": [
    "### Multi requests ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08bf23f1-b0fa-496a-bad4-8db073ba3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch_request(encoded_images, url):\n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, json={\"images\": encoded_images})\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return elapsed_time, response.json()\n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38dcca48-fda0-47f6-9709-c57d67954fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concurrent_batch_test(encoded_images, url, num_requests):\n",
    "   \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(test_batch_request, encoded_images, url) for _ in range(num_requests)]\n",
    "        results = [f.result() for f in concurrent.futures.as_completed(futures)]\n",
    "    \n",
    "    results = [result for result in results if result is not None]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15cfefa1-8980-462f-9388-77a0437316a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch test with 50 concurrent requests...\n",
      "Average latency: 5.9855 seconds\n"
     ]
    }
   ],
   "source": [
    "def run_load_test_batch(url, sample_image, batch_size, num_requests):\n",
    "\n",
    "    encoded_image = base64_encode(sample_image)\n",
    "    encoded_images = [encoded_image] * batch_size\n",
    "\n",
    "    print(f\"Starting batch test with {num_requests} concurrent requests...\")\n",
    "    test_results = concurrent_batch_test(encoded_images, url, num_requests)\n",
    "\n",
    "    latencies = [result[0] for result in test_results]\n",
    "    average_latency = sum(latencies) / len(latencies)\n",
    "    print(f\"Average latency: {average_latency:.4f} seconds\")\n",
    "  \n",
    "run_load_test_batch(\"http://localhost:9000/predict/\", \"public/sample_images/sample_cat.jpeg\", 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd9b7a-950f-4ac4-ad49-0fb3c763f551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7082cb-7a97-4f24-ab74-ab63382955ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
